{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data used to teach\n",
    "train_data = datasets.MNIST(\"./localTrainingData/\", train=True, download=True, transform=transforms.Compose([\n",
    "    # things we want to apply to the data goes in here\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "# data the model hasn't seen, used to test\n",
    "test_data = datasets.MNIST(\"./localTestingData/\", train=False, download=True, transform=transforms.Compose([\n",
    "    # things we want to apply to the data goes in here\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size = how many we want to pass into our model at a time, generally use 8 - 64 - the larger, the quicker we can train, but not too big or accuracy might be low\n",
    "# we have to batch because data is so big we can't fit it all in at once\n",
    "train_set = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([0, 4, 1, 0, 4, 7, 9, 2, 8, 1])]\n"
     ]
    }
   ],
   "source": [
    "for data in train_set:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x,y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "# if model can find shorter path to decreasing loss, it'll take that path\n",
    "# as optimiser is decreasing loss, it doesn't know how low it can get, so it'll try to lower loss as quickly and easily as possible\n",
    "# if majority of data is 3 or 7, it will start to always predict 3, and will be stuck there forever \n",
    "# this is why we need to balance data\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in train_set:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i] / total * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define layers\n",
    "        # fc1 = fully connected layer 1\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        # where 784 = 28 * 28 because our images are 28x28, can't pass the image, we pass the flattened image or just a flat line of pixels\n",
    "        # where 64 = can be whatever we want\n",
    "        # where nn.Linear = just means fully connected\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        # because fc1 (first layer) outputs 64, second layer MUST take in 64\n",
    "        # fc2 (second layer) can output whatever we want again\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        # output 10 = because number of classes in our numbers is 10 (0,1,2,...,9)\n",
    "\n",
    "    # simple neural network also called FeedForward network, since data passes from one side to the other, nothing else\n",
    "    # this method defines how data flows through our network\n",
    "    def forward(self, x):\n",
    "        #where x is input\n",
    "\n",
    "        # we just pass x (input) through our layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # where relu = Rectified Linear - this is our activation function\n",
    "        # activation function = whether or not neuron is firing\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # activation function is being run on the output of each layer. Because layer 4 outputs 10, we want to return probability that a number is what the neural network thinks it is\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3270, -2.4094, -2.2300, -2.3589, -2.2448, -2.4045, -2.3835, -2.2375,\n",
       "         -2.2478, -2.2105]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = x.view(-1, 28 * 28)\n",
    "# where -1 = specifies this input will be of unknown shape\n",
    "# where 28 = width, height of image being input\n",
    "\n",
    "# this passes info into neural network\n",
    "output = net(X)\n",
    "\n",
    "output\n",
    "# outputs grad_fn = kinda like accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
